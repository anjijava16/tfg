package cat.marc.uni.tfg;

import java.util.*;
import java.util.regex.Pattern;

import breeze.linalg.trace;
import org.apache.avro.ipc.DatagramServer;
import org.apache.spark.SparkContext;
import org.apache.spark.api.java.JavaRDD;
import org.apache.spark.api.java.function.*;
import org.apache.spark.ml.feature.StringIndexerModel;
import org.apache.spark.ml.linalg.Vectors;
import org.apache.spark.sql.*;
import org.apache.spark.sql.types.DataTypes;
import org.apache.spark.sql.types.StructField;

import org.apache.spark.sql.types.StructType;
import scala.Array;
import scala.Tuple2;

import org.apache.spark.SparkConf;
import org.apache.spark.api.java.StorageLevels;
import org.apache.spark.streaming.Durations;
import org.apache.spark.streaming.api.java.JavaDStream;
import org.apache.spark.streaming.api.java.JavaPairDStream;
import org.apache.spark.streaming.api.java.JavaReceiverInputDStream;
import org.apache.spark.streaming.api.java.JavaStreamingContext;

import cat.marc.uni.tfg.Trace;

import javax.xml.crypto.Data;

/**
 * Counts words in UTF8 encoded, '\n' delimited text received from the network every second.
 *
 * Usage: JavaNetworkWordCount <hostname> <port>
 * <hostname> and <port> describe the TCP server that Spark Streaming would connect to receive data.
 *
 * To run this on your local machine, you need to first run a Netcat server
 *    `$ nc -lk 9999`
 * and then run the example
 *    `$ bin/run-example org.apache.spark.examples.streaming.JavaNetworkWordCount localhost 9999`
 */
public final class TraceReceiverBACKUP {
    private static final Pattern COMA = Pattern.compile(",");
    private static final Pattern SPACE = Pattern.compile(" ");
    private static final Pattern NEWLINE = Pattern.compile("\n");

    private static ArrayList<Trace> traces_array = new ArrayList<Trace>();

    private static SQLContext sqc;
    private static JavaStreamingContext ssc;

    public static void main(String[] args) throws Exception {
        if (args.length < 2) {
            System.err.println("Usage: JavaNetworkWordCount <hostname> <port>");
            System.exit(1);
        }

        // Create the context with a 1 second batch size
        SparkConf sparkConf = new SparkConf().setAppName("JavaNetworkWordCount");
        ssc = new JavaStreamingContext(sparkConf, Durations.seconds(5));
        //SQLContext sqc = new SQLContext(SparkSession.builder().getOrCreate());
         sqc = new SQLContext(SparkSession.builder().getOrCreate());


        // Create a JavaReceiverInputDStream on target ip:port and count the
        // words in input stream of \n delimited text (eg. generated by 'nc')
        // Note that no duplication in storage level only for running locally.
        // Replication necessary in distributed scenario for fault tolerance.
        JavaReceiverInputDStream<String> lines = ssc.socketTextStream(
                "localhost", 31337, StorageLevels.MEMORY_AND_DISK_SER);


        /*
        JavaDStream<String> traces = lines.flatMap(new FlatMapFunction<String, String>() {
            @Override
            public Iterator<String> call(String x) {
                return Arrays.asList(NEWLINE.split(x)).iterator();
            }
        });
        */

        //ArrayList<List<String>> trace_accomulator = new ArrayList<List<String>>();

        // <NEW TEST>
        /*
        JavaRDD<Trace> urlsRDD = lines
                .map(new Function<String, Trace>() {
                    @Override
                    public Trace call(String line) throws Exception {
                        String[] parts = line.split("\\t");
                        Trace tra = new Trace();
                        //url.setValue(parts[0].replaceAll("[", ""));

                        return tra;
                    }
                });

        */
        // </NEW TEST>




        lines.foreachRDD((JavaRDD<String> rdd) -> {
            System.out.println("HEYHEYHYEHYEHYE");
            if (!rdd.isEmpty()) {

                List<StructField> fields = Arrays.asList(DataTypes.createStructField("line", DataTypes.StringType, true));
                StructType schema = DataTypes.createStructType(fields);

                clearArray();

                //ArrayList<Row> rows = new ArrayList<Row>();

                rdd.foreach((String s) -> {
                    List<String> a = Arrays.asList(COMA.split(s));
                    //List<StructField> fields = Arrays.asList(DataTypes.createStructField("line", DataTypes.StringType, true));
                    //StructType schema = DataTypes.createStructType(fields);
                    //Dataset df = sqc.createDataFrame(a, schema);
                    Trace t = new Trace();
                    //System.out.println(a.get(0));
                    /*
                    t.protocol = Integer.parseInt(a.get(0));
                    t.src_port = Integer.parseInt(a.get(1));
                    t.dest_port = Integer.parseInt(a.get(2));
                    t.packets = Integer.parseInt(a.get(3));
                    t.bytes = Integer.parseInt(a.get(4));
                    t.start_time = Double.parseDouble(a.get(5));
                    t.end_time = Double.parseDouble(a.get(6));
                    t.duration = Double.parseDouble(a.get(7));
                    t.bytesXpakts = Integer.parseInt(a.get(8));
                    t.ToS = Integer.parseInt(a.get(9));
                    t.urg = Integer.parseInt(a.get(10));
                    t.ack = Integer.parseInt(a.get(11));
                    t.psh = Integer.parseInt(a.get(12));
                    t.rst = Integer.parseInt(a.get(13));
                    t.syn = Integer.parseInt(a.get(14));
                    t.fin = Integer.parseInt(a.get(15));
                    */

                    t.setProtocol(Integer.parseInt(a.get(0)));
                    t.setSrc_port(Integer.parseInt(a.get(1)));
                    t.setDest_port(Integer.parseInt(a.get(2)));
                    t.setPackets(Integer.parseInt(a.get(3)));
                    t.setBytes(Integer.parseInt(a.get(4)));
                    t.setStart_time(Double.parseDouble(a.get(5)));
                    t.setEnd_time(Double.parseDouble(a.get(6)));
                    t.setDuration(Double.parseDouble(a.get(7)));
                    t.setBytesXpakts(Integer.parseInt(a.get(8)));
                    t.setToS(Integer.parseInt(a.get(9)));
                    t.setUrg(Integer.parseInt(a.get(10)));
                    t.setAck(Integer.parseInt(a.get(11)));
                    t.setPsh(Integer.parseInt(a.get(12)));
                    t.setRst(Integer.parseInt(a.get(13)));
                    t.setSyn(Integer.parseInt(a.get(14)));
                    t.setFin(Integer.parseInt(a.get(15)));

                    //System.out.println("NEW TRACE: " + t.toString());

                    //System.out.println("TAMANY ABANS: " + ts.size());
                    //ts.add(t);
                    addTrace(t);
                    //System.out.println("TAMANY DESPRES: " + ts.size());

                    //sqc.createDataFrame(ts, Trace.class).show();

                    /*
                    for (int i = 0; i < a.size(); ++i) {
                        System.out.println("Element " + i + ": " + a.get(i));
                    }
                    */

                    //System.out.println("Aixo es un string d'un rdd: " + s); // CADA LINIA ES UN STRING

                    //Row row = RowFactory.create(s);

                    //Dataset df = sqc.createDataFrame(ts, Trace.class);

                    //rows.add(row);
                    //System.out.println("TAMANAY ROW: " + rows.size());


                });

                Dataset ds = createDF();


                //System.out.println("TAmANY ROW FORA: " + rows.size());
                //sqc.createDataFrame(rows, schema).show();

                //System.out.println(ts.size());
                //sqc.createDataFrame(ts, Trace.class).show();
                //Dataset df = createDF();
                //df.show(10);
                /*
                rdd.flatMap(new FlatMapFunction<String, String>() {
                    @Override
                    public Iterator<String> call(String x) {
                        return Arrays.asList(NEWLINE.split(x)).iterator();
                    });
                });
                */

                //System.out.println(rdd.collect());   // CRIDAR AQUI LES FUNCIONS PER MODIFICAR LA ENTRADA
                //trace_accomulator.add(rdd.collect());
                //System.out.println(trace_accomulator.size());
            }
        });

        /*
        System.out.println("");
        System.out.println("");
        System.out.println("");
        System.out.println("***************** NEW BATCH ****************");
        System.out.println("TRACE ACCOMULATROR SIZE: " + trace_accomulator.size());
        for (int i = 0; i < trace_accomulator.size(); ++i) {

            System.out.println(i);
        }
        System.out.println("------------------ END BATCH ----------------");
        System.out.println("");
        System.out.println("");
        System.out.println("");
        */


        // NOSE XK ARA EM DIU QUE NO TROBA EL METODE FOREACH RDD
        /*
        traces.foreachRDD(new Function<JavaRDD<String>, List<String>>() {
            @Override
            public List<String> call(JavaRDD<String> traces) throws Exception {
                //List<String> result = new List<String>();
                if (traces != null) {
                    List<String> result = traces.collect(); // NO VA XK COLLECT NO RETORNA UN STRING, RETORNA UN LIST<STRING>
                    return result;
                }
                else {
                    return Collections.<String> emptyList();
                }
            }
        });
        */

        /*
        lines.foreachRDD(new Function<JavaRDD<String>, Void>() {
            public Void call(JavaRDD<String> rdd) throws Exception {
                if(rdd != null) {
                    List<String> result = rdd.collect();
                    double[] d = new double[69];
                    int i = 0;

                    for (String temp : result) {
                        double aDouble = Double.parseDouble(temp);
                        d[i]=aDouble;
                        i++;
                        //list_transactions.add(Vectors.dense(d));
                    }
                }
                return  null;
            }
        });
        */

        /*
        traces.foreachRDD(new Function<JavaRDD<String>, ArrayList<String>>() {
            @Override
            public ArrayList<String> call(JavaRDD<String> traces) throws Exception {
                ArrayList<String> result = new ArrayList<String>();
                if (traces != null) {
                    String s = traces.collect(); // NO VA XK COLLECT NO RETORNA UN STRING, RETORNA UN LIST<STRING>
                    result.add(s);
                }
                return result;
            }
        });
        */


        //traces.map(RowFactory::create);
        //List<StructField> fields = Arrays.asList(DataTypes.createStructField("line", DataTypes.StringType, true));
        //StructType schema = DataTypes.createStructType(fields);
        //DataFrame df = createDataFrame(rowRDD, schema);


        /*
        ArrayList<Trace> t = new ArrayList<Trace>();

        traces.foreachRDD(new VoidFunction<String>() {
            @Override
            public void call(String stringJavaRDD) throws Exception {

            }
        });

            String aux_trace = _.collet();
            Trace new_trace = new Trace();
            new_trace.protocol = ;
            new_trace.src_port = ;
            new_trace.dest_port = ;
            new_trace.packets = ;
            new_trace.bytes = ;
            new_trace.start_time = ;
            new_trace.end_time = ;
            new_trace.duration = ;
            new_trace.bytesXpakts = ;
            new_trace.ToS = ;
            new_trace.urg = ;
            new_trace.ack = ;
            new_trace.psh = ;
            new_trace.rst =
            new_trace.syn = ;
            new_trace.fin = ;


            t.add(new_trace);
        };
        */

        /*
        JavaDStream<Trace> traces_structured = traces.flatMap(new FlatMapFunction<String, String>() {
            @Override
            public Iterator<Trace> call(Trace x) {
                return Arrays.asList(NEWLINE.split(x)).iterator();
            }
        });

        JavaPairDStream<String, Integer> wordCounts = traces.mapToPair(
                new PairFunction<String, String, Integer>() {
                    @Override
                    public Tuple2<String, Integer> call(String s) {
                        return new Tuple2<>(s, 1);
                    }
                }).reduceByKey(new Function2<Integer, Integer, Integer>() {
            @Override
            public Integer call(Integer i1, Integer i2) {
                return i1 + i2;
            }
        });
        */

        //wordCounts.print();
        ssc.start();
        ssc.awaitTermination();
    }

    private static void clearArray() {
        System.out.println("Clearing Array...");
        traces_array = new ArrayList<Trace>();
    }

    private static void addTrace(Trace t) {
        System.out.println("Adding new trace...");
        traces_array.add(t);
        System.out.println("Size of Array is: " + traces_array.size());
    }

    private static Dataset createDF() {

        System.out.println("Creating DataFrame with Array of size: " + traces_array.size());
        Dataset ds = sqc.createDataFrame(traces_array, Trace.class);
        //ds.toDF().show();
        //System.out.println("COUNT: " + ds.count());
        //ds.printSchema();
        //String[] aux_s = ds.schema().fieldNames();
        //System.out.println("TAMANY AUX_S: " + aux_s.length);
        //for (int i = 0; i < aux_s.length; ++i) {
        //    System.out.println("Camp " + i + ": " + aux_s[i]);
        //}
        return ds;

        //List<Trace> aux_l = traces_array;
        //JavaRDD<Trace> inputRDD = sqc.parallelize(aux_l);

        //Dataset dataframe = sqc.createDataFrame(inputRDD, Trace.class);
        //return dataframe;

    }
}